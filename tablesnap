import pyinotify
import boto

from optparse import OptionParser
from traceback import format_exc
from threading import Thread
import logging
import os.path
import socket
import json
import sys
import os
import re

log = logging.getLogger('tablesnap')
stderr = logging.StreamHandler()
stderr.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))
log.addHandler(stderr)
log.setLevel(logging.DEBUG)


class UploadHandler(pyinotify.ProcessEvent):
    def my_init(self, bucket=None, prefix=None, regex=None):
        self.bucket = bucket
        self.prefix = prefix
        self.regex = regex
#        self.hostname = socket.getfqdn()

    def process_IN_MOVED_TO(self, event):
        if event.pathname.find('-tmp') == -1:
            filename = event.pathname.split("/")[-1]
            keyname = '%s/%s' % (self.prefix, filename)
            key = self.bucket.get_key(keyname)
            if key is None:
                t = Thread(target=self.upload_sstable, args=(
                           keyname, event.pathname, filename))
                t.setDaemon(True)
                t.start()
            else:
                log.warning("Keyname %s already exists, skipping upload" % keyname)

    def upload_sstable(self, keyname, filename, name, with_index=True):
        log.info('Uploading %s' % filename)

        def progress(sent, total):
            if sent == total:
                log.info('Finished uploading %s' % filename)

        log.debug("upload: %s - %s - %s" % (self.bucket.name, keyname, filename))
        if self.regex and not re.match(self.regex, name):
            log.debug('%s did not match %s, skipping' % (filename, self.regex))
            return

        try:
            dirname = os.path.dirname(filename)
            if with_index:
                key = self.bucket.new_key('%s-listdir.json' % keyname)
                key.set_contents_from_string(
                    json.dumps({dirname: os.listdir(dirname)}))

            key = self.bucket.new_key(keyname)
            key.set_contents_from_filename(filename, replace=False, cb=progress)
        except:
            log.error('Error uploading %s\n%s' % (keyname, format_exc()))


def backup_files(handler, bucket, prefix, path, regex):
    log.info('Backing up %s' % path)
    for filename in os.listdir(path):
        if filename.find('-tmp') != -1:
            continue
        keyname = '%s/%s' % (prefix, filename)
        if not bucket.get_key(keyname):
            handler.upload_sstable(keyname, '%s/%s' % (path, filename), filename, with_index=False)
        else:
            log.info('Not uploading %s/%s, it already exists in this S3 bucket.' % (path, filename))
    return 0


def main():
    parser = OptionParser(usage='%prog [options] <bucket:prefix:path:regex> [...]')
    parser.add_option('-k', '--aws-key', dest='aws_key', default=None)
    parser.add_option('-s', '--aws-secret', dest='aws_secret', default=None)
    parser.add_option('-r', '--recursive', action='store_true', dest='recursive', default=False,
        help='Recursively watch the given path(s)s for new SSTables')
    parser.add_option('-a', '--auto-add', action='store_true', dest='auto_add', default=False,
        help='Automatically start watching new subdirectories within path(s)')
    parser.add_option('-B', '--backup', action='store_true', dest='backup',
        help='Backup existing SSTables to S3 if they\'re not already there')
    options, args = parser.parse_args()

    if len(args) < 1:
        parser.print_help()
        return -1

    s3 = boto.connect_s3(options.aws_key, options.aws_secret)

    for arg in args:
        if len(arg.split(":")) != 4:
           log.critical("all 4 of bucket:prefix:path:regex is required (blank is allowed for prefix and regex)")
           return -1

    wm = pyinotify.WatchManager()
    notifier = pyinotify.Notifier(wm)
    for arg in args:
        conf = arg.split(":")
        bucket = conf[0]
        prefix = conf[1].rstrip("/")
        path = conf[2]
        regex = conf[3]

        bucket = s3.get_bucket(bucket)
        handler = UploadHandler(bucket=bucket, prefix=prefix, regex=regex)

        if options.backup:
            backup_files(handler, bucket, prefix, path, regex)
            continue

        ret = wm.add_watch(path, pyinotify.ALL_EVENTS, proc_fun=handler, rec=options.recursive, auto_add=options.auto_add)
        if ret[path] == -1:
            log.critical('add_watch failed for %s, bailing out!' % path)
            return 1
    log.info('looping notifier')
    notifier.loop()

if __name__ == '__main__':
    sys.exit(main())
